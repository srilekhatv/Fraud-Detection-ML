{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "915cb645-aa68-448f-9638-cce9af512ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/akshaythakare/Downloads/fake_job_postings.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe57e62d-382f-41ac-813b-56def7873a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_id                     0\n",
       "title                      0\n",
       "location                 346\n",
       "department             11547\n",
       "salary_range           15012\n",
       "company_profile         3308\n",
       "description                1\n",
       "requirements            2696\n",
       "benefits                7212\n",
       "telecommuting              0\n",
       "has_company_logo           0\n",
       "has_questions              0\n",
       "employment_type         3471\n",
       "required_experience     7050\n",
       "required_education      8105\n",
       "industry                4903\n",
       "function                6455\n",
       "fraudulent                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa3d0695-4a7a-4972-aecb-c9c365629adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in text columns with an empty string\n",
    "text_columns = ['title', 'location', 'department', 'company_profile', 'description', 'requirements', 'benefits', 'industry']\n",
    "for col in text_columns:\n",
    "    data[col] = data[col].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc808925-416a-4fde-90f9-61098ac8d399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_id                     0\n",
       "title                      0\n",
       "location                   0\n",
       "department                 0\n",
       "salary_range           15012\n",
       "company_profile            0\n",
       "description                0\n",
       "requirements               0\n",
       "benefits                   0\n",
       "telecommuting              0\n",
       "has_company_logo           0\n",
       "has_questions              0\n",
       "employment_type         3471\n",
       "required_experience     7050\n",
       "required_education      8105\n",
       "industry                   0\n",
       "function                6455\n",
       "fraudulent                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ae9ee9a-334a-469a-bed3-16319918ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary indicator for missing salary values\n",
    "data['salary_missing'] = data['salary_range'].isnull().astype(int)\n",
    "\n",
    "# Define a function to process the salary range into a numeric format\n",
    "def process_salary(salary):\n",
    "    if pd.isnull(salary):\n",
    "        return np.nan\n",
    "    salary_range = salary.split('-')\n",
    "    try:\n",
    "        return (float(salary_range[0]) + float(salary_range[1])) / 2\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function to convert salary range to numeric\n",
    "data['salary'] = data['salary_range'].apply(process_salary)\n",
    "\n",
    "# Impute salary based on experience level, then education level, and finally with overall median\n",
    "data['salary'] = data.groupby('required_experience')['salary'].transform(lambda x: x.fillna(x.median()))\n",
    "data['salary'] = data.groupby('required_education')['salary'].transform(lambda x: x.fillna(x.median()))\n",
    "data['salary'] = data['salary'].fillna(data['salary'].median())\n",
    "\n",
    "# Drop the original 'salary_range' column as it's now converted\n",
    "data.drop(columns=['salary_range'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fcc45a6-48dc-4c46-b939-9a52827f2202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_id                    0\n",
       "title                     0\n",
       "location                  0\n",
       "department                0\n",
       "company_profile           0\n",
       "description               0\n",
       "requirements              0\n",
       "benefits                  0\n",
       "telecommuting             0\n",
       "has_company_logo          0\n",
       "has_questions             0\n",
       "employment_type        3471\n",
       "required_experience    7050\n",
       "required_education     8105\n",
       "industry                  0\n",
       "function               6455\n",
       "fraudulent                0\n",
       "salary_missing            0\n",
       "salary                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87fe4052-d881-4ea1-a5d1-e60295710a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2m/6n8651_j1vz7qclc1y39fx8c0000gn/T/ipykernel_35309/2596888426.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['employment_type'].fillna(data['employment_type'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data['employment_type'].fillna(data['employment_type'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38b59c86-5f7d-4f66-acbd-058aaa87c246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_id                    0\n",
       "title                     0\n",
       "location                  0\n",
       "department                0\n",
       "company_profile           0\n",
       "description               0\n",
       "requirements              0\n",
       "benefits                  0\n",
       "telecommuting             0\n",
       "has_company_logo          0\n",
       "has_questions             0\n",
       "employment_type           0\n",
       "required_experience    7050\n",
       "required_education     8105\n",
       "industry                  0\n",
       "function               6455\n",
       "fraudulent                0\n",
       "salary_missing            0\n",
       "salary                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee26e467-6981-4c6f-bec6-f9c55eff1849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert required experience to numeric value\n",
    "def process_experience(experience):\n",
    "    if pd.isnull(experience):\n",
    "        return np.nan\n",
    "    exp_range = experience.split('-')\n",
    "    try:\n",
    "        return (float(exp_range[0]) + float(exp_range[1])) / 2\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "data['experience'] = data['required_experience'].apply(process_experience)\n",
    "\n",
    "# Impute missing experience values based on the median within each education group\n",
    "data['experience'] = data.groupby('required_education')['experience'].transform(lambda x: x.fillna(x.median()))\n",
    "data['experience'] = data['experience'].fillna(data['experience'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "713c6004-76b5-4a67-87ae-52910822c337",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['experience'] = data['experience'].fillna(data['experience'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9aa76a29-63ca-47fb-beab-9a4553919f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2m/6n8651_j1vz7qclc1y39fx8c0000gn/T/ipykernel_35309/1260417444.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['required_education'].fillna(data['required_education'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing education values with the mode\n",
    "data['required_education'].fillna(data['required_education'].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1ce2ca8-6358-4db2-8cdc-f4a54f3a4560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2m/6n8651_j1vz7qclc1y39fx8c0000gn/T/ipykernel_35309/799071214.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['function'].fillna(data['function'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data['function'].fillna(data['function'].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56635d70-4425-43ef-8b6a-8cf56753fc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2m/6n8651_j1vz7qclc1y39fx8c0000gn/T/ipykernel_35309/3243412594.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['experience'].fillna(data['experience'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Impute missing 'experience' values based on education level, then employment type\n",
    "data['experience'] = data.groupby('required_education')['experience'].transform(lambda x: x.fillna(x.median()))\n",
    "data['experience'] = data.groupby('employment_type')['experience'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# If there are still missing values, fill them with the overall median of 'experience'\n",
    "data['experience'].fillna(data['experience'].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fbfa4f4-ac37-4639-84cd-c310ea3b0406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_id                     0\n",
       "title                      0\n",
       "location                   0\n",
       "department                 0\n",
       "company_profile            0\n",
       "description                0\n",
       "requirements               0\n",
       "benefits                   0\n",
       "telecommuting              0\n",
       "has_company_logo           0\n",
       "has_questions              0\n",
       "employment_type            0\n",
       "required_experience     7050\n",
       "required_education         0\n",
       "industry                   0\n",
       "function                   0\n",
       "fraudulent                 0\n",
       "salary_missing             0\n",
       "salary                     0\n",
       "experience             17880\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0447c1e8-2d06-4803-9be8-37b8ffcc8176",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['experience','required_experience'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b5b396b-f347-41ec-8b78-7dbb3751f94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_id                0\n",
       "title                 0\n",
       "location              0\n",
       "department            0\n",
       "company_profile       0\n",
       "description           0\n",
       "requirements          0\n",
       "benefits              0\n",
       "telecommuting         0\n",
       "has_company_logo      0\n",
       "has_questions         0\n",
       "employment_type       0\n",
       "required_education    0\n",
       "industry              0\n",
       "function              0\n",
       "fraudulent            0\n",
       "salary_missing        0\n",
       "salary                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "815daa5e-34ac-44f7-b9c3-0a56796127c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>company_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>required_education</th>\n",
       "      <th>industry</th>\n",
       "      <th>function</th>\n",
       "      <th>fraudulent</th>\n",
       "      <th>salary_missing</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Marketing Intern</td>\n",
       "      <td>US, NY, New York</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>Experience with content management systems a m...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td></td>\n",
       "      <td>Marketing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Customer Service - Cloud Video Production</td>\n",
       "      <td>NZ, , Auckland</td>\n",
       "      <td>Success</td>\n",
       "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>What we expect from you:Your key responsibilit...</td>\n",
       "      <td>What you will get from usThrough being part of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
       "      <td>US, IA, Wever</td>\n",
       "      <td></td>\n",
       "      <td>Valor Services provides Workforce Solutions th...</td>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>Implement pre-commissioning and commissioning ...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td></td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Account Executive - Washington DC</td>\n",
       "      <td>US, DC, Washington</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Our passion for improving quality of life thro...</td>\n",
       "      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n",
       "      <td>EDUCATION: Bachelor’s or Master’s in GIS, busi...</td>\n",
       "      <td>Our culture is anything but corporate—we have ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>69750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bill Review Manager</td>\n",
       "      <td>US, FL, Fort Worth</td>\n",
       "      <td></td>\n",
       "      <td>SpotSource Solutions LLC is a Global Human Cap...</td>\n",
       "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
       "      <td>QUALIFICATIONS:RN license in the State of Texa...</td>\n",
       "      <td>Full Benefits Offered</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Hospital &amp; Health Care</td>\n",
       "      <td>Health Care Provider</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>69750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Accounting Clerk</td>\n",
       "      <td>US, MD,</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Job OverviewApex is an environmental consultin...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td></td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Head of Content (m/f)</td>\n",
       "      <td>DE, BE, Berlin</td>\n",
       "      <td>ANDROIDPIT</td>\n",
       "      <td>Founded in 2009, the Fonpit AG rose with its i...</td>\n",
       "      <td>Your Responsibilities: Manage the English-spea...</td>\n",
       "      <td>Your Know-How:                                ...</td>\n",
       "      <td>Your Benefits: Being part of a fast-growing co...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Master's Degree</td>\n",
       "      <td>Online Media</td>\n",
       "      <td>Management</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Lead Guest Service Specialist</td>\n",
       "      <td>US, CA, San Francisco</td>\n",
       "      <td></td>\n",
       "      <td>Airenvy’s mission is to provide lucrative yet ...</td>\n",
       "      <td>Who is Airenvy?Hey there! We are seasoned entr...</td>\n",
       "      <td>Experience with CRM software, live chat, and p...</td>\n",
       "      <td>Competitive Pay. You'll be able to eat steak e...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td></td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>HP BSM SME</td>\n",
       "      <td>US, FL, Pensacola</td>\n",
       "      <td></td>\n",
       "      <td>Solutions3 is a woman-owned small business who...</td>\n",
       "      <td>Implementation/Configuration/Testing/Training ...</td>\n",
       "      <td>MUST BE A US CITIZEN.An active TS/SCI clearanc...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Information Technology and Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Customer Service Associate - Part Time</td>\n",
       "      <td>US, AZ, Phoenix</td>\n",
       "      <td></td>\n",
       "      <td>Novitex Enterprise Solutions, formerly Pitney ...</td>\n",
       "      <td>The Customer Service Associate will be based i...</td>\n",
       "      <td>Minimum Requirements:Minimum of 6 months custo...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>High School or equivalent</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id                                      title               location  \\\n",
       "0       1                           Marketing Intern       US, NY, New York   \n",
       "1       2  Customer Service - Cloud Video Production         NZ, , Auckland   \n",
       "2       3    Commissioning Machinery Assistant (CMA)          US, IA, Wever   \n",
       "3       4          Account Executive - Washington DC     US, DC, Washington   \n",
       "4       5                        Bill Review Manager     US, FL, Fort Worth   \n",
       "5       6                           Accounting Clerk               US, MD,    \n",
       "6       7                      Head of Content (m/f)         DE, BE, Berlin   \n",
       "7       8           Lead Guest Service Specialist     US, CA, San Francisco   \n",
       "8       9                                 HP BSM SME      US, FL, Pensacola   \n",
       "9      10    Customer Service Associate - Part Time         US, AZ, Phoenix   \n",
       "\n",
       "   department                                    company_profile  \\\n",
       "0   Marketing  We're Food52, and we've created a groundbreaki...   \n",
       "1     Success  90 Seconds, the worlds Cloud Video Production ...   \n",
       "2              Valor Services provides Workforce Solutions th...   \n",
       "3       Sales  Our passion for improving quality of life thro...   \n",
       "4              SpotSource Solutions LLC is a Global Human Cap...   \n",
       "5                                                                  \n",
       "6  ANDROIDPIT  Founded in 2009, the Fonpit AG rose with its i...   \n",
       "7              Airenvy’s mission is to provide lucrative yet ...   \n",
       "8              Solutions3 is a woman-owned small business who...   \n",
       "9              Novitex Enterprise Solutions, formerly Pitney ...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Food52, a fast-growing, James Beard Award-winn...   \n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...   \n",
       "2  Our client, located in Houston, is actively se...   \n",
       "3  THE COMPANY: ESRI – Environmental Systems Rese...   \n",
       "4  JOB TITLE: Itemization Review ManagerLOCATION:...   \n",
       "5  Job OverviewApex is an environmental consultin...   \n",
       "6  Your Responsibilities: Manage the English-spea...   \n",
       "7  Who is Airenvy?Hey there! We are seasoned entr...   \n",
       "8  Implementation/Configuration/Testing/Training ...   \n",
       "9  The Customer Service Associate will be based i...   \n",
       "\n",
       "                                        requirements  \\\n",
       "0  Experience with content management systems a m...   \n",
       "1  What we expect from you:Your key responsibilit...   \n",
       "2  Implement pre-commissioning and commissioning ...   \n",
       "3  EDUCATION: Bachelor’s or Master’s in GIS, busi...   \n",
       "4  QUALIFICATIONS:RN license in the State of Texa...   \n",
       "5                                                      \n",
       "6  Your Know-How:                                ...   \n",
       "7  Experience with CRM software, live chat, and p...   \n",
       "8  MUST BE A US CITIZEN.An active TS/SCI clearanc...   \n",
       "9  Minimum Requirements:Minimum of 6 months custo...   \n",
       "\n",
       "                                            benefits  telecommuting  \\\n",
       "0                                                                 0   \n",
       "1  What you will get from usThrough being part of...              0   \n",
       "2                                                                 0   \n",
       "3  Our culture is anything but corporate—we have ...              0   \n",
       "4                              Full Benefits Offered              0   \n",
       "5                                                                 0   \n",
       "6  Your Benefits: Being part of a fast-growing co...              0   \n",
       "7  Competitive Pay. You'll be able to eat steak e...              0   \n",
       "8                                                                 0   \n",
       "9                                                                 0   \n",
       "\n",
       "   has_company_logo  has_questions employment_type         required_education  \\\n",
       "0                 1              0           Other          Bachelor's Degree   \n",
       "1                 1              0       Full-time          Bachelor's Degree   \n",
       "2                 1              0       Full-time          Bachelor's Degree   \n",
       "3                 1              0       Full-time          Bachelor's Degree   \n",
       "4                 1              1       Full-time          Bachelor's Degree   \n",
       "5                 0              0       Full-time          Bachelor's Degree   \n",
       "6                 1              1       Full-time            Master's Degree   \n",
       "7                 1              1       Full-time          Bachelor's Degree   \n",
       "8                 1              1       Full-time          Bachelor's Degree   \n",
       "9                 1              0       Part-time  High School or equivalent   \n",
       "\n",
       "                              industry                function  fraudulent  \\\n",
       "0                                                    Marketing           0   \n",
       "1            Marketing and Advertising        Customer Service           0   \n",
       "2                                       Information Technology           0   \n",
       "3                    Computer Software                   Sales           0   \n",
       "4               Hospital & Health Care    Health Care Provider           0   \n",
       "5                                       Information Technology           0   \n",
       "6                         Online Media              Management           0   \n",
       "7                                       Information Technology           0   \n",
       "8  Information Technology and Services  Information Technology           0   \n",
       "9                   Financial Services        Customer Service           0   \n",
       "\n",
       "   salary_missing   salary  \n",
       "0               1  40000.0  \n",
       "1               1  40000.0  \n",
       "2               1  40000.0  \n",
       "3               1  69750.0  \n",
       "4               1  69750.0  \n",
       "5               1  40000.0  \n",
       "6               0  24000.0  \n",
       "7               1  40000.0  \n",
       "8               1  40000.0  \n",
       "9               1  29000.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d91746-9b67-4ff6-8f02-627b1195360f",
   "metadata": {},
   "source": [
    "## Bernouli with smote "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4d9a7f1e-02e3-4c72-8f64-46fd51b322bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91\n",
      "Classification Report for Bernoulli Naive Bayes with SMOTE (no PCA):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91      5105\n",
      "           1       0.90      0.91      0.91      5104\n",
      "\n",
      "    accuracy                           0.91     10209\n",
      "   macro avg       0.91      0.91      0.91     10209\n",
      "weighted avg       0.91      0.91      0.91     10209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Step 1: Combine the text columns into 'combined_text'\n",
    "text_columns = ['title', 'location', 'department', 'company_profile', 'description', 'requirements', 'benefits']\n",
    "data['combined_text'] = data[text_columns].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Step 2: Vectorize text features using CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "text_features = vectorizer.fit_transform(data['combined_text'])\n",
    "\n",
    "# Step 3: Separate numeric features\n",
    "numeric_features = ['telecommuting', 'has_company_logo', 'has_questions']  # example numeric features\n",
    "X_numeric = data[numeric_features].values\n",
    "y = data['fraudulent']\n",
    "\n",
    "# Step 4: Convert numeric features to sparse matrix for consistency\n",
    "X_numeric_sparse = csr_matrix(X_numeric)\n",
    "\n",
    "# Step 5: Combine text features and numeric features\n",
    "X_combined = hstack([text_features, X_numeric_sparse])\n",
    "\n",
    "# Step 6: Apply SMOTE to the combined features (text + numeric)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_combined_smote, y_smote = smote.fit_resample(X_combined, y)\n",
    "\n",
    "# Step 7: Split into train and test (ensure you have a proper split before model training)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined_smote, y_smote, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 8: Train Exact Bayes (using BernoulliNB) on the resampled data\n",
    "bernoulli_model = BernoulliNB(alpha=1.0)  # You can adjust alpha\n",
    "bernoulli_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 9: Evaluate the model\n",
    "y_pred = bernoulli_model.predict(X_test)  # Make predictions on the test set\n",
    "\n",
    "# Step 10: Evaluate accuracy and classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"Classification Report for Bernoulli Naive Bayes with SMOTE (no PCA):\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c5578d-fad9-448e-8de0-99d14d1a20b1",
   "metadata": {},
   "source": [
    "## Dialer System for Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dcf53d73-64b6-4808-8f72-3a06f06174d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold: 0.02\n",
      "Accuracy: 0.9053776079929474\n",
      "Confusion Matrix:\n",
      " [[4558  547]\n",
      " [ 419 4685]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90      5105\n",
      "           1       0.90      0.92      0.91      5104\n",
      "\n",
      "    accuracy                           0.91     10209\n",
      "   macro avg       0.91      0.91      0.91     10209\n",
      "weighted avg       0.91      0.91      0.91     10209\n",
      "\n",
      "\n",
      "Threshold: 0.01\n",
      "Accuracy: 0.9051817024194339\n",
      "Confusion Matrix:\n",
      " [[4552  553]\n",
      " [ 415 4689]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90      5105\n",
      "           1       0.89      0.92      0.91      5104\n",
      "\n",
      "    accuracy                           0.91     10209\n",
      "   macro avg       0.91      0.91      0.91     10209\n",
      "weighted avg       0.91      0.91      0.91     10209\n",
      "\n",
      "\n",
      "Threshold: 0.0001\n",
      "Accuracy: 0.905083749632677\n",
      "Confusion Matrix:\n",
      " [[4504  601]\n",
      " [ 368 4736]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90      5105\n",
      "           1       0.89      0.93      0.91      5104\n",
      "\n",
      "    accuracy                           0.91     10209\n",
      "   macro avg       0.91      0.91      0.91     10209\n",
      "weighted avg       0.91      0.91      0.91     10209\n",
      "\n",
      "\n",
      "Threshold: 0.03\n",
      "Accuracy: 0.9048878440591634\n",
      "Confusion Matrix:\n",
      " [[4558  547]\n",
      " [ 424 4680]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90      5105\n",
      "           1       0.90      0.92      0.91      5104\n",
      "\n",
      "    accuracy                           0.90     10209\n",
      "   macro avg       0.91      0.90      0.90     10209\n",
      "weighted avg       0.91      0.90      0.90     10209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Train Bernoulli Naive Bayes and generate probabilities\n",
    "def bernoulli_bayes_probabilities(X_train, y_train, X_test):\n",
    "    # Initialize and train the Bernoulli Naive Bayes model\n",
    "    model = BernoulliNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the predicted probabilities for the test data\n",
    "    probabilities = model.predict_proba(X_test)  # Probability for each class (0 and 1)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "# Dialer system to test different thresholds\n",
    "def dialer_system(y_true, probabilities, thresholds=[0.3, 0.4, 0.5, 0.6, 0.7]):\n",
    "    for threshold in thresholds:\n",
    "        # Generate predictions based on threshold for fraudulent (class 1)\n",
    "        y_pred = [1 if prob[1] >= threshold else 0 for prob in probabilities]\n",
    "\n",
    "        # Display performance metrics\n",
    "        print(f\"\\nThreshold: {threshold}\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "        print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n",
    "\n",
    "# Assuming you have already split the data into training and test sets\n",
    "# X_train, X_test, y_train, y_test\n",
    "\n",
    "# Generate probabilities with Bernoulli Naive Bayes and apply the dialer system\n",
    "probabilities = bernoulli_bayes_probabilities(X_train, y_train, X_test)\n",
    "dialer_system(y_test, probabilities, thresholds=[0.02,0.01,0.0001, 0.03])  # Adjust thresholds as needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821567a6-c66a-46d5-894d-d7b903265bfb",
   "metadata": {},
   "source": [
    "## Exact bayes with smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c099ebc3-6e38-42fb-9f3e-40823ee15d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Bayes Model Accuracy with SMOTE (no PCA): 0.94\n",
      "Exact Bayes Model Evaluation with SMOTE (no PCA):\n",
      "Confusion Matrix:\n",
      " [[4785  320]\n",
      " [ 310 4794]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      5105\n",
      "           1       0.94      0.94      0.94      5104\n",
      "\n",
      "    accuracy                           0.94     10209\n",
      "   macro avg       0.94      0.94      0.94     10209\n",
      "weighted avg       0.94      0.94      0.94     10209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Step 1: Combine the text columns into 'combined_text'\n",
    "text_columns = ['title', 'location', 'department', 'company_profile', 'description', 'requirements', 'benefits']\n",
    "data['combined_text'] = data[text_columns].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Step 2: Vectorize text features using CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "text_features = vectorizer.fit_transform(data['combined_text'])\n",
    "\n",
    "# Step 3: Separate numeric features\n",
    "numeric_features = ['telecommuting', 'has_company_logo', 'has_questions']  # example numeric features\n",
    "X_numeric = data[numeric_features].values\n",
    "y = data['fraudulent']\n",
    "\n",
    "# Step 4: Convert numeric features to sparse matrix for consistency\n",
    "X_numeric_sparse = csr_matrix(X_numeric)\n",
    "\n",
    "# Step 5: Combine text features and numeric features\n",
    "X_combined = hstack([text_features, X_numeric_sparse])\n",
    "\n",
    "# Step 6: Apply SMOTE to the combined features (text + numeric)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_combined_smote, y_smote = smote.fit_resample(X_combined, y)\n",
    "\n",
    "# Step 7: Split into train and test (ensure you have a proper split before model training)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined_smote, y_smote, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 8: Exact Bayes (Custom model, assuming it's implemented like above)\n",
    "def exact_bayes_predict(X_train, y_train, X_test):\n",
    "    classes = np.unique(y_train)\n",
    "    class_probs = {}\n",
    "    conditional_probs = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
    "\n",
    "    # Calculate prior probabilities and conditional probabilities\n",
    "    for c in classes:\n",
    "        X_class = X_train[y_train == c]\n",
    "        class_probs[c] = X_class.shape[0] / y_train.shape[0]  # Use .shape[0] for sparse matrices\n",
    "        \n",
    "        # Calculate conditional probabilities for each feature\n",
    "        for col in range(X_train.shape[1]):  # Handle sparse matrix indexing\n",
    "            col_values = X_class[:, col].toarray().flatten()  # Convert to dense array and flatten\n",
    "            unique_vals = np.unique(col_values)\n",
    "            for val in unique_vals:\n",
    "                conditional_probs[c][col][val] = np.sum(col_values == val) / len(col_values)\n",
    "\n",
    "    # Make predictions on test data\n",
    "    predictions = []\n",
    "    for row in X_test:\n",
    "        class_scores = {}\n",
    "        row_dense = row.toarray().flatten()  # Convert sparse row to dense\n",
    "        for c in classes:\n",
    "            score = np.log(class_probs[c])  # Use log probabilities for numerical stability\n",
    "            for col in range(X_train.shape[1]):\n",
    "                val = row_dense[col]\n",
    "                score += np.log(conditional_probs[c][col].get(val, 1e-6))  # Laplace smoothing for unseen values\n",
    "            class_scores[c] = score\n",
    "        predictions.append(max(class_scores, key=class_scores.get))\n",
    "    return predictions\n",
    "\n",
    "# Step 9: Predict with Exact Bayes model\n",
    "y_pred_exact_bayes = exact_bayes_predict(X_train, y_train, X_test)\n",
    "\n",
    "# Step 10: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred_exact_bayes)\n",
    "print(f\"Exact Bayes Model Accuracy with SMOTE (no PCA): {accuracy:.2f}\")\n",
    "\n",
    "print(\"Exact Bayes Model Evaluation with SMOTE (no PCA):\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_exact_bayes))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_exact_bayes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89d50a2-75c6-4024-8cc3-5f3458775800",
   "metadata": {},
   "source": [
    "## Dialer For Exact Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ab9cde38-a78c-4b72-a1cf-e41a6fe92618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold: 0.5\n",
      "Accuracy: 0.7041825839945146\n",
      "Confusion Matrix:\n",
      " [[2169 2936]\n",
      " [  84 5020]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.42      0.59      5105\n",
      "           1       0.63      0.98      0.77      5104\n",
      "\n",
      "    accuracy                           0.70     10209\n",
      "   macro avg       0.80      0.70      0.68     10209\n",
      "weighted avg       0.80      0.70      0.68     10209\n",
      "\n",
      "\n",
      "Threshold: 0.7\n",
      "Accuracy: 0.9104711529043001\n",
      "Confusion Matrix:\n",
      " [[4789  316]\n",
      " [ 598 4506]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      5105\n",
      "           1       0.93      0.88      0.91      5104\n",
      "\n",
      "    accuracy                           0.91     10209\n",
      "   macro avg       0.91      0.91      0.91     10209\n",
      "weighted avg       0.91      0.91      0.91     10209\n",
      "\n",
      "\n",
      "Threshold: 0.8\n",
      "Accuracy: 0.9099813889705162\n",
      "Confusion Matrix:\n",
      " [[4790  315]\n",
      " [ 604 4500]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      5105\n",
      "           1       0.93      0.88      0.91      5104\n",
      "\n",
      "    accuracy                           0.91     10209\n",
      "   macro avg       0.91      0.91      0.91     10209\n",
      "weighted avg       0.91      0.91      0.91     10209\n",
      "\n",
      "\n",
      "Threshold: 0.9\n",
      "Accuracy: 0.9108629640513273\n",
      "Confusion Matrix:\n",
      " [[4800  305]\n",
      " [ 605 4499]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      5105\n",
      "           1       0.94      0.88      0.91      5104\n",
      "\n",
      "    accuracy                           0.91     10209\n",
      "   macro avg       0.91      0.91      0.91     10209\n",
      "weighted avg       0.91      0.91      0.91     10209\n",
      "\n",
      "\n",
      "Threshold: 1.0\n",
      "Accuracy: 0.9077284748751102\n",
      "Confusion Matrix:\n",
      " [[4955  150]\n",
      " [ 792 4312]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91      5105\n",
      "           1       0.97      0.84      0.90      5104\n",
      "\n",
      "    accuracy                           0.91     10209\n",
      "   macro avg       0.91      0.91      0.91     10209\n",
      "weighted avg       0.91      0.91      0.91     10209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "\n",
    "# Dialer system to test different thresholds for Exact Bayes model\n",
    "def dialer_system_exact_bayes(X_train, y_train, X_test, y_true, thresholds=[0.3, 0.4, 0.5, 0.6, 0.7]):\n",
    "    # Calculate prior probabilities for each class\n",
    "    class_probs = {}\n",
    "    for c in np.unique(y_train):\n",
    "        class_probs[c] = np.sum(y_train == c) / len(y_train)\n",
    "    \n",
    "    # Calculate conditional probabilities (you have this already in the exact_bayes_predict function)\n",
    "    conditional_probs = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
    "    for c in np.unique(y_train):\n",
    "        X_class = X_train[y_train == c]\n",
    "        for col in range(X_train.shape[1]):  # Handle sparse matrix indexing\n",
    "            col_values = X_class[:, col].toarray().flatten()  # Convert to dense array and flatten\n",
    "            unique_vals = np.unique(col_values)\n",
    "            for val in unique_vals:\n",
    "                conditional_probs[c][col][val] = np.sum(col_values == val) / len(col_values)\n",
    "\n",
    "    # Now, let's make predictions and calculate probabilities for each sample\n",
    "    class_probs_output = []\n",
    "    \n",
    "    for row in X_test:\n",
    "        row_dense = row.toarray().flatten()  # Convert sparse row to dense\n",
    "        class_scores = {}\n",
    "        for c in np.unique(y_train):\n",
    "            score = np.log(class_probs[c])  # Start with log-prior\n",
    "            for col in range(X_train.shape[1]):\n",
    "                val = row_dense[col]\n",
    "                # Ensure we don't get zero probability\n",
    "                score += np.log(conditional_probs[c][col].get(val, 1e-6))  # Laplace smoothing for unseen values\n",
    "            class_scores[c] = score\n",
    "        \n",
    "        # Ensure that neither score is NaN or infinite\n",
    "        if np.isfinite(class_scores[0]) and np.isfinite(class_scores[1]):\n",
    "            # Softmax-like scaling\n",
    "            exp_scores = np.exp(np.array([class_scores[0], class_scores[1]]))\n",
    "            if np.sum(exp_scores) == 0:\n",
    "                prob_class_1 = 0.5  # If both scores are zero, default to 50%\n",
    "            else:\n",
    "                prob_class_1 = exp_scores[1] / np.sum(exp_scores)\n",
    "        else:\n",
    "            prob_class_1 = 0.5  # Default to 50% if there's an issue with the score calculation (e.g., NaN or -inf)\n",
    "        \n",
    "        class_probs_output.append(prob_class_1)\n",
    "\n",
    "    # Now apply the threshold to the predicted probabilities\n",
    "    for threshold in thresholds:\n",
    "        y_pred = [1 if prob >= threshold else 0 for prob in class_probs_output]\n",
    "\n",
    "        # Display performance metrics\n",
    "        print(f\"\\nThreshold: {threshold}\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "        print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n",
    "\n",
    "# Example usage (assuming you have already split the data into X_train, X_test, y_train, y_test)\n",
    "# Dialer system for Exact Bayes\n",
    "dialer_system_exact_bayes(X_train, y_train, X_test, y_test, thresholds=[0.5,0.7,0.8, 0.9,1.0])  # Adjust thresholds as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b253aad8-a4b3-4aa8-b7ef-1915acf7adcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
